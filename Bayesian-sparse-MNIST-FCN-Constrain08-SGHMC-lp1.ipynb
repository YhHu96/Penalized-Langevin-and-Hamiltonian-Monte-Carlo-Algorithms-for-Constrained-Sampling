{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06f9929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levy_stable\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import os\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75bcfa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet(nn.Module):\n",
    "# a simple fully connected neural network\n",
    "    def __init__(self, input_dim=28*28 , width=400, depth=4, num_classes=10):\n",
    "        super(simpleNet, self).__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        layers = self.get_layers()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.width, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            *layers,\n",
    "            nn.Linear(self.width, self.num_classes, bias=False),\n",
    "        )\n",
    "\n",
    "    def get_layers(self):\n",
    "        layers = []\n",
    "        for i in range(self.depth - 2):\n",
    "            layers.append(nn.Linear(self.width, self.width, bias=False))\n",
    "            layers.append(nn.ReLU())\n",
    "        return layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), self.input_dim)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2175aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data\n",
    "batch_size=128\n",
    "data_tf = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=(0.1307,), std=(0.3081,))])\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=data_tf, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=data_tf)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "695822ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGLD(Optimizer):\n",
    "    \"\"\"\n",
    "    SGLD optimiser based on pytorch's SGD.\n",
    "    Note that the weight decay is specified in terms of the gaussian prior sigma.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr, norm_sigma=0, addnoise=True):\n",
    "\n",
    "        weight_decay = 1 / (norm_sigma ** 2)\n",
    "\n",
    "        if weight_decay < 0.0:\n",
    "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "\n",
    "        defaults = dict(lr=lr, weight_decay=weight_decay, addnoise=addnoise)\n",
    "\n",
    "        super(SGLD, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Performs a single optimization step.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            weight_decay = group['weight_decay']\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                if weight_decay != 0:\n",
    "                    d_p.add_(weight_decay, p.data)\n",
    "\n",
    "                if group['addnoise']:\n",
    "\n",
    "                    langevin_noise = p.data.new(p.data.size()).normal_(mean=0, std=1) / np.sqrt(group['lr'])\n",
    "                    p.data.add_(-group['lr'],\n",
    "                                0.5 * d_p + langevin_noise)\n",
    "                else:\n",
    "                    p.data.add_(-group['lr'], 0.5 * d_p)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7e9a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "class PSGHMC(Optimizer):\n",
    "    '''\n",
    "    Penalized SGHMC algorithm\n",
    "    '''\n",
    "\n",
    "    def __init__(self, params, lr, delta, gamma, constrain_list, lp = 1):\n",
    "        if lr < 0.0:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "\n",
    "        defaults = dict(lr=lr, delta=delta, gamma = gamma, constrain_list = constrain_list, lp = lp)\n",
    "        super(PSGHMC, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(PSGHMC, self).__setstate__(state)\n",
    "        for group in self.param_groups:\n",
    "            group.setdefault('nesterov', False)\n",
    "        \n",
    "#     functions to calculate covariance between two independent noise\n",
    "    def phi0(self, t, gamma):\n",
    "        return torch.exp(torch.tensor(-t * gamma))\n",
    "\n",
    "    def phi1(self, t, gamma):\n",
    "        return - 1/gamma * torch.exp(torch.tensor(-t * gamma)) + 1 / gamma\n",
    "\n",
    "    def phi2(self, t, gamma):\n",
    "        tmp = 1/gamma ** 2\n",
    "        tmp = tmp * (torch.exp(torch.tensor(-gamma*t))-1)\n",
    "        tmp = tmp + t/gamma\n",
    "        return tmp\n",
    "\n",
    "    def covariance(self, t, gamma):\n",
    "        e2gt = np.exp(-gamma*t*2)\n",
    "        egt = np.exp(-gamma*t)\n",
    "        a11 = - (1/(2*gamma)) * e2gt + 1/(2*gamma)\n",
    "        a12 = e2gt / (2*gamma*gamma) - egt/(gamma**2) - 1/(2*(gamma**2)) + 1/(gamma ** 2)\n",
    "        a22 = -e2gt/(2*(gamma ** 3)) + 2*egt / (gamma**3) + 1/(2 * (gamma ** 3)) - 2/(gamma ** 3) + t/(gamma ** 2)\n",
    "        tmp = np.array([[a11, a12], [a12,a22]])\n",
    "        return tmp\n",
    "    \n",
    "#     generate related noise based on covariance\n",
    "    def gen_noise(self, t, gamma, dim):\n",
    "        cov = self.covariance(t, gamma)\n",
    "        rand = np.random.multivariate_normal([0]*2, cov, size = (dim))\n",
    "        rand1 = rand[:, :, 0]\n",
    "        rand2 = rand[:, :, 1]\n",
    "        return torch.tensor(rand1).cuda(), torch.tensor(rand2).cuda()\n",
    "    \n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            delta = group['delta']\n",
    "            constrain_list = group['constrain_list']\n",
    "            lp = group['lp']\n",
    "            lr = group['lr']\n",
    "            gamma = group['gamma']\n",
    "            \n",
    "            idx = 0\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                d_p = p.grad.data\n",
    "                norm_ord = torch.norm(p.data, p = lp)\n",
    "                constrain = constrain_list[idx]\n",
    "                if norm_ord > constrain:\n",
    "                    g1 = torch.pow(torch.abs(p.data)/norm_ord, lp-1)\n",
    "                    tmp_con = (norm_ord-constrain) * (g1 * torch.sign(p.data))\n",
    "                    d_p.add_(delta, tmp_con)\n",
    "                \n",
    "                noise1, noise2 = self.gen_noise(lr, gamma, p.data.shape)\n",
    "                \n",
    "                param_state = self.state[p]\n",
    "                if 'momentum_buffer' not in param_state:\n",
    "                    buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
    "                else:\n",
    "                    buf = param_state['momentum_buffer']\n",
    "                    buf.mul_(self.phi0(lr, gamma)).add_(-self.phi1(lr, gamma), d_p).add_(torch.sqrt(torch.tensor(2*gamma)), noise1)\n",
    "\n",
    "                p.data.add_(self.phi1(lr, gamma), buf).add_(-self.phi2(lr, gamma), d_p).add_(torch.sqrt(torch.tensor(2*gamma)), noise2)\n",
    "                idx += 1\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e85ae76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.4459\n",
      "0.6184333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:360: UserWarning: Couldn't retrieve source code for container of type simpleNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7102166666666667\n",
      "0.7923\n",
      "0.8310833333333333\n",
      "0.8534166666666667\n",
      "0.86655\n",
      "0.8743666666666666\n",
      "1\n",
      "0.6074166666666667\n",
      "0.6786\n",
      "0.7121666666666666\n",
      "0.7804666666666666\n",
      "0.8149166666666666\n",
      "0.8388833333333333\n",
      "0.8552833333333333\n",
      "0.8663166666666666\n",
      "2\n",
      "0.5657\n",
      "0.5825666666666667\n",
      "0.7217666666666667\n",
      "0.8001333333333334\n",
      "0.8353166666666667\n",
      "0.8557333333333333\n",
      "0.8675333333333334\n",
      "0.8753333333333333\n",
      "3\n",
      "0.6229333333333333\n",
      "0.6082166666666666\n",
      "0.70935\n",
      "0.7892166666666667\n",
      "0.8232833333333334\n",
      "0.84565\n",
      "0.85935\n",
      "0.8697166666666667\n",
      "4\n",
      "0.5727\n",
      "0.6400166666666667\n",
      "0.751\n",
      "0.8071833333333334\n",
      "0.84065\n",
      "0.8593166666666666\n",
      "0.8709833333333333\n",
      "0.8778333333333334\n"
     ]
    }
   ],
   "source": [
    "lr_list = [5 * (0.1)**8]\n",
    "delta = (0.1) ** 3\n",
    "\n",
    "# 1-norm of the result from SGLD, used as the constraints in the constrained network\n",
    "norm_list = torch.tensor([5677.8647 , 4067.0469 , 4065.2566 ,  150.35751])\n",
    "# we can change the value of s here\n",
    "constrain_list = norm_list * 0.8\n",
    "\n",
    "# select 1-norm\n",
    "lp = 1\n",
    "epoch = 400\n",
    "# calculate the averaged result from 5 runs\n",
    "N = 5\n",
    "gamma = 0.1\n",
    "\n",
    "# path to save models\n",
    "PATH = './MNIST-3FCN-Pen/constrain08/SGHMC/lp1'\n",
    "try:\n",
    "    os.mkdir(PATH)\n",
    "except OSError as exc:\n",
    "    pass\n",
    "\n",
    "\n",
    "train_acc_all = []\n",
    "\n",
    "for n in range(N):\n",
    "    print(n)\n",
    "    for i in range(len(lr_list)):\n",
    "        learning_rate = lr_list[i]\n",
    "        trainErrorList=[]\n",
    "        trainAccList=[]\n",
    "\n",
    "\n",
    "        model = simpleNet()\n",
    "        if torch.cuda.is_available():\n",
    "                model = model.cuda()\n",
    "        criterion = nn.functional.nll_loss\n",
    "    #     optimizer = SGLD(model.parameters(), lr = learning_rate, norm_sigma = 1, addnoise = True)\n",
    "        optimizer = PSGHMC(model.parameters(), lr=learning_rate, delta = delta, gamma = gamma, constrain_list = constrain_list, lp = lp)\n",
    "        scheduler = StepLR(optimizer, step_size=50, gamma=0.9)\n",
    "        \n",
    "        for l in range(epoch):\n",
    "            train_acc=0\n",
    "            for data in train_loader:\n",
    "                img, label = data\n",
    "                img=img.view(img.size(0),-1)\n",
    "                if torch.cuda.is_available():\n",
    "                    img = img.cuda()\n",
    "                    label = label.cuda()\n",
    "                else:\n",
    "                    img = Variable(img)\n",
    "                    label = Variable(label)\n",
    "                out = model(img)\n",
    "                loss = F.cross_entropy(out, label, reduction='sum')\n",
    "    #             loss = criterion(out, label)\n",
    "                print_loss = loss.data.item()\n",
    "                _, pred = torch.max(out.data, 1)\n",
    "                train_acc += pred.eq(label.view_as(pred)).sum().item()\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            trainErrorList.append(loss.data.item())\n",
    "            trainAccList.append(train_acc/60000)\n",
    "            scheduler.step()\n",
    "            if l % 50 == 0 and l !=0:\n",
    "                print(train_acc/60000)\n",
    "            if (train_acc/60000) >=0.7 and train_acc/60000 == max(trainAccList):\n",
    "                tmp_path = PATH + '/model' + '{}'.format(n) +'.pth'\n",
    "                torch.save(model, tmp_path)\n",
    "        train_acc_all.append(trainAccList)\n",
    "        print(train_acc/60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df686934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
